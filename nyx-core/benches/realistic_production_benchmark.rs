//! üöÄ ÂÆüÈÅãÁî®NyxNetÈ´òÊÄßËÉΩ„Éô„É≥„ÉÅ„Éû„Éº„ÇØ
//! 
//! ÂÆüÈöõ„ÅÆÂåøÂêç„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ‰ΩøÁî®„Éë„Çø„Éº„É≥„Çí„Ç∑„Éü„É•„É¨„Éº„Éà:
//! - Web„Éñ„É©„Ç¶„Ç∏„É≥„Ç∞„ÄÅ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞„ÄÅ„Éï„Ç°„Ç§„É´Ëª¢ÈÄÅ
//! - Ë§áÊï∞„É¶„Éº„Ç∂„ÉºÂêåÊôÇÊé•Á∂ö
//! - „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØË≤†Ëç∑„ÉªÂà∂Á¥ÑÊù°‰ª∂
//! - „É°„É¢„É™ÂäπÁéá„Å®„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ

use criterion::{black_box, criterion_group, criterion_main, BenchmarkId, Criterion, Throughput};
use nyx_core::performance::RateLimiter;
use nyx_transport::{UdpEndpoint, TransportManager, TransportRequirements};
use nyx_stream::async_stream::{pair, AsyncStreamConfig};
use nyx_stream::performance::StreamMetrics;
use bytes::Bytes;
use std::time::Duration;
use tokio::runtime::Runtime;
use std::sync::Arc;
use futures::future;

// ÂÆüÈöõ„ÅÆ„Éà„É©„Éï„Ç£„ÉÉ„ÇØ„Éë„Çø„Éº„É≥„Å´Âü∫„Å•„Åè„É°„ÉÉ„Çª„Éº„Ç∏„Çµ„Ç§„Ç∫
const SMALL_MSG: usize = 512;     // Âà∂Âæ°„É°„ÉÉ„Çª„Éº„Ç∏
const MEDIUM_MSG: usize = 1420;   // Ê®ôÊ∫ñMTU„Éö„Ç§„É≠„Éº„Éâ
const LARGE_MSG: usize = 8192;    // „Éï„Ç°„Ç§„É´Ëª¢ÈÄÅ„ÉÅ„É£„É≥„ÇØ
const BURST_MSG: usize = 32768;   // Â§ßÂÆπÈáè„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ

/// „Éô„É≥„ÉÅ„Éû„Éº„ÇØ: Web„Éñ„É©„Ç¶„Ç∏„É≥„Ç∞„Ç∑„Éä„É™„Ç™
/// ÊúÄ„ÇÇ‰∏ÄËà¨ÁöÑ„Å™‰ΩøÁî®„Ç±„Éº„Çπ
fn bench_web_browsing_scenarios(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("üåê_web_browsing");
    group.sample_size(30);
    group.measurement_time(Duration::from_secs(6));
    
    let scenarios = [
        ("text_page", SMALL_MSG, 10),
        ("image_page", MEDIUM_MSG, 20),  // 50->20„Å´ÂâäÊ∏õ
        ("video_stream", LARGE_MSG, 30), // 100->30„Å´ÂâäÊ∏õ
        ("file_download", BURST_MSG, 50), // 200->50„Å´ÂâäÊ∏õ
    ];
    
    for (name, size, count) in scenarios {
        group.throughput(Throughput::Bytes((size * count) as u64));
        group.bench_with_input(BenchmarkId::new("scenario", name), &(size, count), |b, &(msg_size, msg_count)| {
            b.to_async(&rt).iter(|| async {
                let config = AsyncStreamConfig {
                    max_inflight: 64,
                    retransmit_timeout: Duration::from_millis(50),
                    ..Default::default()
                };
                
                let (sender, receiver) = pair(config.clone(), config);
                
                // ‰∏¶Ë°å„Åß„É°„ÉÉ„Çª„Éº„Ç∏ÈÄÅÂèó‰ø°
                let send_task = tokio::spawn(async move {
                    for i in 0..msg_count {
                        let data = Bytes::from(vec![42u8; msg_size]);
                        if sender.send(data).await.is_err() {
                            break;
                        }
                        
                        // „É™„Ç¢„É´„Å™„É¶„Éº„Ç∂„ÉºÊìç‰ΩúÈñìÈöî
                        if i % 10 == 0 {
                            tokio::time::sleep(Duration::from_micros(50)).await;
                        }
                    }
                });
                
                let recv_task = tokio::spawn(async move {
                    let mut received = 0;
                    while received < msg_count {
                        if let Ok(Some(_)) = receiver.recv().await {
                            received += 1;
                        }
                    }
                    received
                });
                
                let (_, received) = tokio::join!(send_task, recv_task);
                black_box(received.unwrap_or(0));
            });
        });
    }
    
    group.finish();
}

/// „Éô„É≥„ÉÅ„Éû„Éº„ÇØ: ÂêåÊôÇÊé•Á∂ö„É¶„Éº„Ç∂„ÉºË≤†Ëç∑
/// „É™„É¨„Éº„Éé„Éº„Éâ„ÅÆÂÆüÈöõ„ÅÆË≤†Ëç∑„Çí„Ç∑„Éü„É•„É¨„Éº„Éà
fn bench_concurrent_users(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    let mut group = c.benchmark_group("üë•_concurrent_users");
    group.sample_size(40);
    group.measurement_time(Duration::from_secs(12));
    
    let user_counts = [1, 5, 10, 25, 50];
    
    for user_count in user_counts {
        group.bench_with_input(BenchmarkId::new("users", user_count), &user_count, |b, &users| {
            b.to_async(&rt).iter(|| async {
                let mut tasks = Vec::new();
                
                for user_id in 0..users {
                    let task = tokio::spawn(async move {
                        let config = AsyncStreamConfig {
                            stream_id: user_id as u32,
                            max_inflight: 16,
                            ..Default::default()
                        };
                        
                        let (send, recv) = pair(config.clone(), config);
                        let mut processed = 0;
                        
                        for i in 0..20 {
                            // „É¨„Éº„ÉàÂà∂Èôê„ÇíÁ∞°Âçò„Å´„Ç∑„Éü„É•„É¨„Éº„Éà
                            if i % 5 == 0 {
                                tokio::time::sleep(Duration::from_micros(100)).await;
                            }
                            
                            let data = Bytes::from(vec![(user_id as u8 + i as u8) % 255; MEDIUM_MSG]);
                            
                            if send.send(data).await.is_ok() {
                                if let Ok(Some(_)) = recv.recv().await {
                                    processed += 1;
                                }
                            }
                        }
                        
                        processed
                    });
                    
                    tasks.push(task);
                }
                
                let results = future::join_all(tasks).await;
                let total: i32 = results.into_iter().map(|r| r.unwrap_or(0)).sum();
                black_box(total);
            });
        });
    }
    
    group.finish();
}

/// „Éô„É≥„ÉÅ„Éû„Éº„ÇØ: „É°„É¢„É™ÂäπÁéá„ÉÜ„Çπ„Éà
/// Èï∑ÊôÇÈñìÈÅãÁî®„Åß„ÅÆÂÆâÂÆöÊÄß
fn bench_memory_efficiency(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    
    c.bench_function("memory_sustained_load", |b| {
        b.to_async(&rt).iter(|| async {
            let metrics = Arc::new(StreamMetrics::new());
            
            let config = AsyncStreamConfig {
                max_inflight: 128,
                ..Default::default()
            };
            
            let (sender, receiver) = pair(config.clone(), config);
            
            // Ë§áÊï∞„Çµ„Ç§„Ç∫„ÅÆ„É°„ÉÉ„Çª„Éº„Ç∏„ÇíÂäπÁéáÁöÑ„Å´Âá¶ÁêÜ
            for size in [SMALL_MSG, MEDIUM_MSG, LARGE_MSG] {
                for i in 0..50 {
                    let data = Bytes::from(vec![(i % 255) as u8; size]);
                    
                    if sender.send(data).await.is_ok() {
                        if let Ok(Some(_)) = receiver.recv().await {
                            // „É°„É¢„É™‰ΩøÁî®Èáè„ÇíÂÆâÂÆö„Å´‰øù„Å§
                        }
                    }
                }
            }
            
            let stats = metrics.frames_sent.load(std::sync::atomic::Ordering::Relaxed);
            black_box(stats);
        });
    });
}

/// „Éô„É≥„ÉÅ„Éû„Éº„ÇØ: „Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂà∂Á¥Ñ‰∏ã„Åß„ÅÆ„Éë„Éï„Ç©„Éº„Éû„É≥„Çπ
/// ÂÆüÈöõ„ÅÆ„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÊù°‰ª∂„Çí„Ç∑„Éü„É•„É¨„Éº„Éà
fn bench_network_conditions(c: &mut Criterion) {
    let mut group = c.benchmark_group("üåê_network_conditions");
    group.sample_size(30);
    group.measurement_time(Duration::from_secs(8));
    
    let conditions = [
        ("optimal", 10),    // 10msÈÅÖÂª∂
        ("good", 50),       // 50msÈÅÖÂª∂
        ("poor", 200),      // 200msÈÅÖÂª∂
        ("mobile", 500),    // 500msÈÅÖÂª∂
    ];
    
    for (condition, latency_ms) in conditions {
        group.bench_with_input(BenchmarkId::new("condition", condition), &latency_ms, |b, &latency| {
            b.iter(|| {
                let rt = Runtime::new().unwrap();
                rt.block_on(async {
                    let transport_manager = TransportManager::new();
                    let requirements = TransportRequirements {
                        requires_reliability: true,
                        prefers_low_latency: latency < 100,
                        max_latency: Some(Duration::from_millis(latency as u64)),
                        ..Default::default()
                    };
                    
                    let _selected = transport_manager.select_transport(&requirements);
                    
                    // UDP„Ç®„É≥„Éâ„Éù„Ç§„É≥„Éà„Åß„ÅÆ„Çπ„Éà„É¨„Çπ„ÉÜ„Çπ„Éà
                    let mut endpoint1 = UdpEndpoint::bind_loopback().unwrap();
                    let mut endpoint2 = UdpEndpoint::bind_loopback().unwrap();
                    let addr2 = endpoint2.local_addr().unwrap();
                    
                    for i in 0..50 {
                        let data = vec![(i % 255) as u8; MEDIUM_MSG];
                        
                        // ÈÅÖÂª∂„Çí„Ç∑„Éü„É•„É¨„Éº„Éà
                        if latency > 50 {
                            std::thread::sleep(Duration::from_micros(latency as u64 * 5));
                        }
                        
                        let _ = endpoint1.send_to_buffered(&data, addr2);
                        
                        if i % 10 == 0 {
                            let mut buf = vec![0u8; MEDIUM_MSG + 100];
                            let _ = endpoint2.recv_from(&mut buf);
                        }
                    }
                    
                    let stats = endpoint1.get_stats();
                    black_box(stats);
                });
            });
        });
    }
    
    group.finish();
}

/// „Éô„É≥„ÉÅ„Éû„Éº„ÇØ: „Ç®„É≥„Éâ„ÉÑ„Éº„Ç®„É≥„ÉâÂÆåÂÖ®„Éï„É≠„Éº
/// 3„Éõ„ÉÉ„ÉóÂåøÂêç„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØ„ÅÆÂÆåÂÖ®„Ç∑„Éü„É•„É¨„Éº„Ç∑„Éß„É≥
fn bench_end_to_end_flow(c: &mut Criterion) {
    let rt = Runtime::new().unwrap();
    
    c.bench_function("üîÑ_complete_anonymity_flow", |b| {
        b.to_async(&rt).iter(|| async {
            let config = AsyncStreamConfig {
                max_inflight: 32,
                retransmit_timeout: Duration::from_millis(100),
                ..Default::default()
            };
            
            // 3„Éõ„ÉÉ„Éó„Éë„Çπ: „ÇØ„É©„Ç§„Ç¢„É≥„Éà -> „Ç¨„Éº„Éâ -> „Éü„Éâ„É´ -> „Ç®„Ç∞„Ç∏„ÉÉ„Éà
            let (client_send, guard_recv) = pair(config.clone(), config.clone());
            let (guard_send, middle_recv) = pair(config.clone(), config.clone());
            let (middle_send, exit_recv) = pair(config.clone(), config);
            
            let web_request = Bytes::from(b"GET /index.html HTTP/1.1\r\nHost: example.com\r\n\r\n".to_vec());
            
            // „ÇØ„É©„Ç§„Ç¢„É≥„Éà„Åå„É™„ÇØ„Ç®„Çπ„ÉàÈÄÅ‰ø°
            let client_task = tokio::spawn(async move {
                client_send.send(web_request).await.ok()
            });
            
            // „Ç¨„Éº„Éâ„É™„É¨„Éº
            let guard_task = tokio::spawn(async move {
                if let Ok(Some(data)) = guard_recv.recv().await {
                    tokio::time::sleep(Duration::from_micros(50)).await;
                    guard_send.send(data).await.ok();
                }
            });
            
            // „Éü„Éâ„É´„É™„É¨„Éº
            let middle_task = tokio::spawn(async move {
                if let Ok(Some(data)) = middle_recv.recv().await {
                    tokio::time::sleep(Duration::from_micros(50)).await;
                    middle_send.send(data).await.ok();
                }
            });
            
            // „Ç®„Ç∞„Ç∏„ÉÉ„Éà„É™„É¨„Éº
            let exit_task = tokio::spawn(async move {
                if let Ok(Some(request)) = exit_recv.recv().await {
                    black_box(request.len());
                    return true;
                }
                false
            });
            
            let (client_result, _, _, exit_result) = tokio::join!(
                client_task, guard_task, middle_task, exit_task
            );
            
            black_box((client_result.unwrap_or(None), exit_result.unwrap_or(false)));
        });
    });
}

criterion_group!(
    production_benchmarks,
    bench_web_browsing_scenarios,
    bench_concurrent_users,
    bench_memory_efficiency,
    bench_network_conditions,
    bench_end_to_end_flow
);

criterion_main!(production_benchmarks);
